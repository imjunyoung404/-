{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imjunyoung404/ai-class-3-2/blob/main/3%EC%A3%BC%EC%B0%A8/%EC%A0%84%EB%B3%B5%20%EB%B6%84%EB%A5%98%EB%A5%BC%20CNN%EC%9C%BC%EB%A1%9C%20%EA%B5%AC%ED%98%84_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 읽어오기\n",
        "df = pd.read_csv(\"/content/abalone (1).csv\")\n",
        "\n",
        "# 데이터 확인\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "F1s0KUsVDFzI",
        "outputId": "89a9b7b7-da59-483d-f2e5-b581402cdbfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
            "0   0   M   0.455     0.365   0.095        0.5140          0.2245   \n",
            "1   1   M   0.350     0.265   0.090        0.2255          0.0995   \n",
            "2   2   F   0.530     0.420   0.135        0.6770          0.2565   \n",
            "3   3   M   0.440     0.365   0.125        0.5160          0.2155   \n",
            "4   4   I   0.330     0.255   0.080        0.2050          0.0895   \n",
            "\n",
            "   Viscera_weight  Shell_weight  Rings  \n",
            "0          0.1010         0.150     15  \n",
            "1          0.0485         0.070      7  \n",
            "2          0.1415         0.210      9  \n",
            "3          0.1140         0.155     10  \n",
            "4          0.0395         0.055      7  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 'Sex' 열을 숫자로 변환 (예: M -> 1, F -> 2, I -> 0)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "\n",
        "# 피처와 타겟 설정\n",
        "X = df.drop('Rings', axis=1).values  # 입력 데이터\n",
        "y = df['Rings'].values  # 타겟 값\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# 데이터 분할 (80% 훈련, 20% 테스트)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WjoSj617DnE4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# CNN 모델 정의\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')  # 'Rings'는 회귀 문제이므로 'linear' 출력층 사용\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test MAE: {test_mae:.2f}')"
      ],
      "metadata": {
        "id": "vm1wU2PFDoq4",
        "outputId": "b8ccaec7-3b36-4f15-a7fd-8944805129f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 63.3596 - mae: 6.7188 - val_loss: 7.4931 - val_mae: 2.0164\n",
            "Epoch 2/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.5042 - mae: 2.1271 - val_loss: 5.6544 - val_mae: 1.6850\n",
            "Epoch 3/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8514 - mae: 1.9577 - val_loss: 5.2733 - val_mae: 1.6277\n",
            "Epoch 4/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.6107 - mae: 1.9423 - val_loss: 5.0232 - val_mae: 1.6014\n",
            "Epoch 5/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7753 - mae: 1.8530 - val_loss: 5.0968 - val_mae: 1.6008\n",
            "Epoch 6/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7403 - mae: 1.8557 - val_loss: 4.8997 - val_mae: 1.5561\n",
            "Epoch 7/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0990 - mae: 1.8091 - val_loss: 4.7901 - val_mae: 1.5561\n",
            "Epoch 8/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.4844 - mae: 1.8444 - val_loss: 4.6487 - val_mae: 1.5401\n",
            "Epoch 9/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8378 - mae: 1.7404 - val_loss: 4.7703 - val_mae: 1.5411\n",
            "Epoch 10/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4062 - mae: 1.7009 - val_loss: 4.6224 - val_mae: 1.5151\n",
            "Epoch 11/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7375 - mae: 1.7233 - val_loss: 4.7520 - val_mae: 1.5607\n",
            "Epoch 12/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7796 - mae: 1.7467 - val_loss: 4.5084 - val_mae: 1.5423\n",
            "Epoch 13/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3259 - mae: 1.6779 - val_loss: 4.5476 - val_mae: 1.5326\n",
            "Epoch 14/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3863 - mae: 1.6837 - val_loss: 4.6713 - val_mae: 1.6036\n",
            "Epoch 15/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3398 - mae: 1.6931 - val_loss: 4.5641 - val_mae: 1.5690\n",
            "Epoch 16/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2141 - mae: 1.6418 - val_loss: 4.6324 - val_mae: 1.6066\n",
            "Epoch 17/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8639 - mae: 1.6307 - val_loss: 4.4451 - val_mae: 1.5116\n",
            "Epoch 18/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1398 - mae: 1.6351 - val_loss: 4.4939 - val_mae: 1.5560\n",
            "Epoch 19/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3121 - mae: 1.6668 - val_loss: 4.4571 - val_mae: 1.5101\n",
            "Epoch 20/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3761 - mae: 1.6489 - val_loss: 4.4495 - val_mae: 1.5569\n",
            "Epoch 21/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1965 - mae: 1.6592 - val_loss: 4.3439 - val_mae: 1.4942\n",
            "Epoch 22/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.3098 - mae: 1.6477 - val_loss: 4.3464 - val_mae: 1.5096\n",
            "Epoch 23/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.6325 - mae: 1.5653 - val_loss: 4.3914 - val_mae: 1.5375\n",
            "Epoch 24/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.1108 - mae: 1.6311 - val_loss: 4.6536 - val_mae: 1.4982\n",
            "Epoch 25/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.9510 - mae: 1.6329 - val_loss: 4.3505 - val_mae: 1.5033\n",
            "Epoch 26/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.7107 - mae: 1.5880 - val_loss: 4.3398 - val_mae: 1.4667\n",
            "Epoch 27/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.9751 - mae: 1.5939 - val_loss: 4.4548 - val_mae: 1.4571\n",
            "Epoch 28/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9149 - mae: 1.5978 - val_loss: 4.2934 - val_mae: 1.4901\n",
            "Epoch 29/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0002 - mae: 1.6185 - val_loss: 4.4086 - val_mae: 1.4697\n",
            "Epoch 30/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4949 - mae: 1.5429 - val_loss: 4.3790 - val_mae: 1.4700\n",
            "Epoch 31/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7050 - mae: 1.5769 - val_loss: 4.3298 - val_mae: 1.4712\n",
            "Epoch 32/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6658 - mae: 1.5810 - val_loss: 4.6623 - val_mae: 1.4655\n",
            "Epoch 33/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5968 - mae: 1.5154 - val_loss: 4.3365 - val_mae: 1.4690\n",
            "Epoch 34/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6397 - mae: 1.5541 - val_loss: 4.3169 - val_mae: 1.4616\n",
            "Epoch 35/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7995 - mae: 1.5666 - val_loss: 4.3774 - val_mae: 1.4482\n",
            "Epoch 36/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7847 - mae: 1.5775 - val_loss: 4.2609 - val_mae: 1.4662\n",
            "Epoch 37/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7947 - mae: 1.5840 - val_loss: 4.3827 - val_mae: 1.5482\n",
            "Epoch 38/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6565 - mae: 1.5693 - val_loss: 4.3931 - val_mae: 1.4590\n",
            "Epoch 39/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5891 - mae: 1.5099 - val_loss: 4.2134 - val_mae: 1.4493\n",
            "Epoch 40/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6175 - mae: 1.5349 - val_loss: 4.2895 - val_mae: 1.4569\n",
            "Epoch 41/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3275 - mae: 1.5063 - val_loss: 4.1799 - val_mae: 1.4573\n",
            "Epoch 42/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6938 - mae: 1.5647 - val_loss: 4.3186 - val_mae: 1.4331\n",
            "Epoch 43/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5835 - mae: 1.5464 - val_loss: 4.3598 - val_mae: 1.4560\n",
            "Epoch 44/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6999 - mae: 1.5605 - val_loss: 4.2536 - val_mae: 1.4653\n",
            "Epoch 45/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7537 - mae: 1.5690 - val_loss: 4.2755 - val_mae: 1.4465\n",
            "Epoch 46/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4906 - mae: 1.5197 - val_loss: 4.3831 - val_mae: 1.4465\n",
            "Epoch 47/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.3744 - mae: 1.5098 - val_loss: 4.8223 - val_mae: 1.5158\n",
            "Epoch 48/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4477 - mae: 1.5112 - val_loss: 4.3287 - val_mae: 1.4573\n",
            "Epoch 49/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4488 - mae: 1.5182 - val_loss: 4.2933 - val_mae: 1.4625\n",
            "Epoch 50/50\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.2704 - mae: 1.5093 - val_loss: 4.4248 - val_mae: 1.4403\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6745 - mae: 1.4534\n",
            "Test MAE: 1.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 저장\n",
        "model.save('abalone_cnn_model.h5')"
      ],
      "metadata": {
        "id": "nbZwE_TaECeA",
        "outputId": "97bc82b0-ca92-48a9-8d9f-af523b2c4f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 불러오기\n",
        "pretrained_model = tf.keras.models.load_model('abalone_cnn_model.h5', custom_objects={'mse': tf.keras.losses.MeanSquaredError}) # explicitly define the 'mse'\n",
        "\n",
        "# 사전학습 모델의 마지막 몇 개 층을 동결\n",
        "for layer in pretrained_model.layers[:-1]:  # 마지막 층만 동결하지 않음\n",
        "    layer.trainable = False\n",
        "\n",
        "# 새로운 층 추가\n",
        "new_model = Sequential(pretrained_model.layers)\n",
        "new_model.add(Dense(128, activation='relu'))\n",
        "new_model.add(Dense(1, activation='linear'))  # 회귀 문제이므로 'linear'\n",
        "\n",
        "# 새로운 모델 컴파일\n",
        "new_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "J8ANLIxwEWw0",
        "outputId": "4bd2243f-f2a8-4f2a-d2e0-60e678bef911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 미세조정 학습\n",
        "history_fine = new_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_mae = new_model.evaluate(X_test, y_test)\n",
        "print(f'Fine-tuned Test MAE: {test_mae:.2f}')"
      ],
      "metadata": {
        "id": "1qeD1wzmEb-N",
        "outputId": "d636ae7b-4fdd-478b-d928-44c524f1d5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 168.6919 - mae: 12.4511 - val_loss: 141.6327 - val_mae: 11.3441\n",
            "Epoch 2/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133.2630 - mae: 11.0215 - val_loss: 112.1434 - val_mae: 10.0460\n",
            "Epoch 3/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 105.3265 - mae: 9.7543 - val_loss: 87.6042 - val_mae: 8.8219\n",
            "Epoch 4/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 81.2358 - mae: 8.4953 - val_loss: 65.8854 - val_mae: 7.5766\n",
            "Epoch 5/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 61.3425 - mae: 7.3084 - val_loss: 46.8709 - val_mae: 6.2891\n",
            "Epoch 6/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 41.8014 - mae: 5.9509 - val_loss: 31.0960 - val_mae: 4.9774\n",
            "Epoch 7/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 28.4925 - mae: 4.7251 - val_loss: 19.4489 - val_mae: 3.7302\n",
            "Epoch 8/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17.0680 - mae: 3.4428 - val_loss: 11.8798 - val_mae: 2.6627\n",
            "Epoch 9/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.2203 - mae: 2.4213 - val_loss: 7.6130 - val_mae: 1.9363\n",
            "Epoch 10/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7559 - mae: 1.8569 - val_loss: 5.5911 - val_mae: 1.5827\n",
            "Epoch 11/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3796 - mae: 1.6023 - val_loss: 4.7771 - val_mae: 1.4636\n",
            "Epoch 12/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5297 - mae: 1.4865 - val_loss: 4.4794 - val_mae: 1.4420\n",
            "Epoch 13/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2134 - mae: 1.4680 - val_loss: 4.3863 - val_mae: 1.4472\n",
            "Epoch 14/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6557 - mae: 1.5168 - val_loss: 4.3572 - val_mae: 1.4532\n",
            "Epoch 15/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9637 - mae: 1.4516 - val_loss: 4.3473 - val_mae: 1.4566\n",
            "Epoch 16/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5677 - mae: 1.5292 - val_loss: 4.3403 - val_mae: 1.4598\n",
            "Epoch 17/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7901 - mae: 1.5598 - val_loss: 4.3406 - val_mae: 1.4596\n",
            "Epoch 18/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.3664 - mae: 1.5055 - val_loss: 4.3361 - val_mae: 1.4623\n",
            "Epoch 19/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2418 - mae: 1.4943 - val_loss: 4.3379 - val_mae: 1.4611\n",
            "Epoch 20/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4862 - mae: 1.5261 - val_loss: 4.3379 - val_mae: 1.4610\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5587 - mae: 1.4778\n",
            "Fine-tuned Test MAE: 1.46\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}